{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data and preprocess\n",
    "\n",
    "We are using [ASAP](https://github.com/Meituan-Dianping/asap) dataset authored by Bu et. al. ASAP is a Chinese restaurant review dataset collected from Dianping App. Reviews are written in Chinese and each review is annotated with a star rating from 1 to 5 and 18 different aspects along with the sentiment. \n",
    "\n",
    "\n",
    "Each aspect category for example Location#Transportation is is labeled as 1(Positive), 0(Neutral), −1(Negative), −2(Not-Mentioned). The data is conveniently splited into train, dev, test dataset already.\n",
    "\n",
    "[jieba](https://github.com/fxsjy/jieba) is used \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.401 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    words = jieba.cut(text)\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def convert_sentiment(score):\n",
    "    if score == -2:\n",
    "        return \"not_mentioned\"\n",
    "    elif score == -1:\n",
    "        return \"negative\"\n",
    "    elif score == 0:\n",
    "        return \"neutral\"\n",
    "    else:  # score == 1\n",
    "        return \"positive\"\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Define aspects, e.g. Food#Appearance, Service#Price, etc.\n",
    "    aspect_columns = [col for col in df.columns if col not in [\"id\", \"review\", \"star\"]]\n",
    "    y = df[aspect_columns]\n",
    "\n",
    "    # Convert sentiment scores to categorical labels\n",
    "    y = df[aspect_columns].astype(\"object\")\n",
    "    for col in y.columns:\n",
    "        y.loc[:, col] = y[col].apply(convert_sentiment)\n",
    "\n",
    "    # Data preprocessing\n",
    "    df[\"processed_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "    return df[\"processed_review\"], y, aspect_columns\n",
    "\n",
    "\n",
    "train_path = \"train.csv\"\n",
    "dev_path = \"dev.csv\"\n",
    "test_path = \"test.csv\"\n",
    "\n",
    "X_train, y_train, aspect_columns = load_and_preprocess_data(train_path)\n",
    "X_dev, y_dev, _ = load_and_preprocess_data(dev_path)\n",
    "X_test, y_test, _ = load_and_preprocess_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36850,), (36850, 18)\n",
      "Dev shape: (4940,), (4940, 18)\n",
      "Test shape: (4940,), (4940, 18)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_review</th>\n",
       "      <th>Location#Transportation</th>\n",
       "      <th>Location#Downtown</th>\n",
       "      <th>Location#Easy_to_find</th>\n",
       "      <th>Service#Queue</th>\n",
       "      <th>Service#Hospitality</th>\n",
       "      <th>Service#Parking</th>\n",
       "      <th>Service#Timely</th>\n",
       "      <th>Price#Level</th>\n",
       "      <th>Price#Cost_effective</th>\n",
       "      <th>Price#Discount</th>\n",
       "      <th>Ambience#Decoration</th>\n",
       "      <th>Ambience#Noise</th>\n",
       "      <th>Ambience#Space</th>\n",
       "      <th>Ambience#Sanitary</th>\n",
       "      <th>Food#Portion</th>\n",
       "      <th>Food#Taste</th>\n",
       "      <th>Food#Appearance</th>\n",
       "      <th>Food#Recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>状元 楼 饭店 第一次 去 ， 因为 地理位置 优越 ： 在 宁波市 和 义 大道 高 、 ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>我 最 爱 他们 家 的 猪手 ， 麻辣 鸡爪 ， 肉片 口磨 ， 道 道菜 都 是 家常菜...</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我 是 比较 喜欢 荣 新馆 的 ， 因为 材料 新鲜 ， 服务 又 好 ， 价格 适中 ，...</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>neutral</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.8 秒杀 的 多嘴 肉蟹 煲 ， 第一天 开业 就 去 了 ， 大众 点评 很 给 力 ...</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>neutral</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>喜欢 KOI 好多年 了 ， 但是 看着 它 的 价格 在 一路 飙涨 ， 真心 是 有点 ...</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>not_mentioned</td>\n",
       "      <td>not_mentioned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    processed_review Location#Transportation  \\\n",
       "0  状元 楼 饭店 第一次 去 ， 因为 地理位置 优越 ： 在 宁波市 和 义 大道 高 、 ...                positive   \n",
       "1  我 最 爱 他们 家 的 猪手 ， 麻辣 鸡爪 ， 肉片 口磨 ， 道 道菜 都 是 家常菜...                positive   \n",
       "2  我 是 比较 喜欢 荣 新馆 的 ， 因为 材料 新鲜 ， 服务 又 好 ， 价格 适中 ，...           not_mentioned   \n",
       "3  8.8 秒杀 的 多嘴 肉蟹 煲 ， 第一天 开业 就 去 了 ， 大众 点评 很 给 力 ...           not_mentioned   \n",
       "4  喜欢 KOI 好多年 了 ， 但是 看着 它 的 价格 在 一路 飙涨 ， 真心 是 有点 ...           not_mentioned   \n",
       "\n",
       "  Location#Downtown Location#Easy_to_find  Service#Queue Service#Hospitality  \\\n",
       "0          positive              positive  not_mentioned            positive   \n",
       "1     not_mentioned         not_mentioned  not_mentioned            positive   \n",
       "2     not_mentioned         not_mentioned  not_mentioned            positive   \n",
       "3     not_mentioned         not_mentioned       negative            positive   \n",
       "4          positive              negative  not_mentioned       not_mentioned   \n",
       "\n",
       "  Service#Parking Service#Timely    Price#Level Price#Cost_effective  \\\n",
       "0   not_mentioned  not_mentioned  not_mentioned        not_mentioned   \n",
       "1   not_mentioned  not_mentioned  not_mentioned        not_mentioned   \n",
       "2   not_mentioned  not_mentioned        neutral        not_mentioned   \n",
       "3   not_mentioned  not_mentioned        neutral        not_mentioned   \n",
       "4   not_mentioned  not_mentioned       positive        not_mentioned   \n",
       "\n",
       "  Price#Discount Ambience#Decoration Ambience#Noise Ambience#Space  \\\n",
       "0  not_mentioned            positive  not_mentioned  not_mentioned   \n",
       "1  not_mentioned       not_mentioned  not_mentioned  not_mentioned   \n",
       "2  not_mentioned       not_mentioned  not_mentioned  not_mentioned   \n",
       "3       positive       not_mentioned  not_mentioned  not_mentioned   \n",
       "4       positive       not_mentioned  not_mentioned  not_mentioned   \n",
       "\n",
       "  Ambience#Sanitary   Food#Portion Food#Taste Food#Appearance Food#Recommend  \n",
       "0     not_mentioned  not_mentioned   positive   not_mentioned  not_mentioned  \n",
       "1          positive  not_mentioned   positive   not_mentioned  not_mentioned  \n",
       "2     not_mentioned  not_mentioned    neutral        positive  not_mentioned  \n",
       "3     not_mentioned       positive   positive   not_mentioned  not_mentioned  \n",
       "4     not_mentioned       positive   positive   not_mentioned  not_mentioned  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Dev shape: {X_dev.shape}, {y_dev.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\\n\")\n",
    "\n",
    "pd.concat([X_train, y_train], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subdirectory for EDA plots\n",
    "OUTPUT_DIR = \"eda_plots\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Bar plot colors for sentiment categories\n",
    "SENTIMENTS = [\"not_mentioned\", \"negative\", \"neutral\", \"positive\"]\n",
    "SENTIMENT_COLORS = {\n",
    "    \"not_mentioned\": \"#808080\",  # Gray\n",
    "    \"negative\": \"#FF0000\",  # Red\n",
    "    \"neutral\": \"#1F77B4\",  # Blue\n",
    "    \"positive\": \"#2CA02C\",  # Green\n",
    "}\n",
    "\n",
    "\n",
    "def plot_aspect_mention_frequency(y, dataset_name):\n",
    "    \"\"\"Plot the frequency of aspect mentions in the dataset.\"\"\"\n",
    "    mention_freq = (y != \"not_mentioned\").mean()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=mention_freq.index, y=mention_freq.values)\n",
    "    plt.title(f\"Aspect Mention Frequency in {dataset_name} Dataset\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Proportion of Reviews Mentioning Aspect\")\n",
    "    annotate_bars(ax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(OUTPUT_DIR, f\"aspect_mention_frequency_{dataset_name}.png\")\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_sentiment_distribution(y, dataset_name):\n",
    "    \"\"\"Plot the sentiment distribution for each aspect in the dataset.\"\"\"\n",
    "    for aspect in y.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.countplot(\n",
    "            data=y,\n",
    "            x=aspect,\n",
    "            order=SENTIMENTS,\n",
    "            hue=aspect,\n",
    "            palette=SENTIMENT_COLORS,\n",
    "            legend=False,\n",
    "        )\n",
    "        plt.title(f\"Sentiment Distribution for {aspect} in {dataset_name} Dataset\")\n",
    "        plt.xlabel(\"Sentiment\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        annotate_bars(ax)\n",
    "        plt.savefig(\n",
    "            os.path.join(\n",
    "                OUTPUT_DIR, f\"sentiment_distribution_{aspect}_{dataset_name}.png\"\n",
    "            )\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def annotate_bars(ax):\n",
    "    \"\"\"Annotate bars with their heights, formatting based on value range.\"\"\"\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if height <= 0:\n",
    "            return\n",
    "        if 0 < height < 1:\n",
    "            annotation_text = f\"{height:.2f}\"\n",
    "        else:\n",
    "            # Format as whole number for other values\n",
    "            annotation_text = f\"{int(height)}\"\n",
    "\n",
    "        ax.annotate(\n",
    "            annotation_text,\n",
    "            (p.get_x() + p.get_width() / 2.0, height),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_aspect_mention_distribution(y, dataset_name):\n",
    "    \"\"\"Plot the distribution of the number of aspects mentioned per review.\"\"\"\n",
    "    num_aspects_mentioned_per_review = (y != \"not_mentioned\").sum(axis=1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.histplot(\n",
    "        num_aspects_mentioned_per_review, bins=range(0, len(y.columns) + 1), kde=False\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Distribution of Number of Aspects Mentioned per Review in {dataset_name} Dataset\"\n",
    "    )\n",
    "    plt.xlabel(\"Number of Aspects Mentioned\")\n",
    "    plt.ylabel(\"Number of Reviews\")\n",
    "    annotate_bars(ax)\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"num_aspects_mentioned_{dataset_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def summarize_dataset(y, dataset_name):\n",
    "    \"\"\"Print summary statistics for the dataset.\"\"\"\n",
    "    print(f\"{dataset_name.capitalize()}\")\n",
    "    print(f\"Total reviews: {len(y)}\")\n",
    "\n",
    "    num_aspects_mentioned_per_review = (y != \"not_mentioned\").sum(axis=1)\n",
    "    avg_mentions = num_aspects_mentioned_per_review.mean()\n",
    "\n",
    "    most_mentioned_aspect = (y != \"not_mentioned\").sum().idxmax()\n",
    "    most_mentioned_aspect_count = (y != \"not_mentioned\").sum().max()\n",
    "    most_mentioned_aspect_percentage = (\n",
    "        (y[most_mentioned_aspect] != \"not_mentioned\").sum() / len(y)\n",
    "    ) * 100\n",
    "\n",
    "    least_mentioned_aspect = (y != \"not_mentioned\").sum().idxmin()\n",
    "    least_mentioned_aspect_count = (y != \"not_mentioned\").sum().min()\n",
    "    least_mentioned_aspect_percentage = (\n",
    "        (y[least_mentioned_aspect] != \"not_mentioned\").sum() / len(y)\n",
    "    ) * 100\n",
    "\n",
    "    print(f\"Average number of aspects mentioned per review: {avg_mentions:.2f}\")\n",
    "    print(\n",
    "        f\"Most frequently mentioned aspect: {most_mentioned_aspect} {most_mentioned_aspect_count} ({most_mentioned_aspect_percentage:.2f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Least frequently mentioned aspect: {least_mentioned_aspect} {least_mentioned_aspect_count} ({least_mentioned_aspect_percentage:.2f}%)\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def perform_eda(y, dataset_name):\n",
    "    plot_aspect_mention_frequency(y, dataset_name)\n",
    "    plot_sentiment_distribution(y, dataset_name)\n",
    "    plot_aspect_mention_distribution(y, dataset_name)\n",
    "    summarize_dataset(y, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Total reviews: 36850\n",
      "Average number of aspects mentioned per review: 5.79\n",
      "Most frequently mentioned aspect: Food#Taste 34872 (94.63%)\n",
      "Least frequently mentioned aspect: Service#Parking 2476 (6.72%)\n",
      "\n",
      "Dev\n",
      "Total reviews: 4940\n",
      "Average number of aspects mentioned per review: 5.89\n",
      "Most frequently mentioned aspect: Food#Taste 4672 (94.57%)\n",
      "Least frequently mentioned aspect: Service#Parking 323 (6.54%)\n",
      "\n",
      "Test\n",
      "Total reviews: 4940\n",
      "Average number of aspects mentioned per review: 5.74\n",
      "Most frequently mentioned aspect: Food#Taste 4679 (94.72%)\n",
      "Least frequently mentioned aspect: Service#Parking 326 (6.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_eda(y_train, \"train\")\n",
    "perform_eda(y_dev, \"dev\")\n",
    "perform_eda(y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Word embedding\n",
    "\n",
    "To perform any sort of training, we need to convert raw string (chars) into vectors so that they can be computed. There are plenty of ways to do it including Bag of Words (BoW), Word2vec, GloVe, etc... \n",
    "\n",
    "We shall try them and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Bidirectional Encoder Representations from Transformers (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1e5ada9b6d47a5af8e4e09d8ed08f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701d3f097e66493a8b0cb331946115ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2bced7dba545f1937ae103e400910d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c200c42e0c4591b6df0d813f8f3b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00817ed3c2f4f38b218c4ca5c1cf014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 2304/2304 [07:44<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Training Loss: 9.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Dev: 100%|██████████| 309/309 [00:26<00:00, 11.51it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev Results:\n",
      "\n",
      "Location#Transportation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.96      0.98      0.97      3964\n",
      "     negative       1.00      0.04      0.08        50\n",
      "      neutral       0.00      0.00      0.00        42\n",
      "     positive       0.89      0.86      0.88       884\n",
      "\n",
      "     accuracy                           0.94      4940\n",
      "    macro avg       0.71      0.47      0.48      4940\n",
      " weighted avg       0.94      0.94      0.94      4940\n",
      "\n",
      "\n",
      "Location#Downtown:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.92      0.96      0.94      4061\n",
      "     negative       0.00      0.00      0.00        23\n",
      "      neutral       0.00      0.00      0.00        26\n",
      "     positive       0.76      0.65      0.70       830\n",
      "\n",
      "     accuracy                           0.90      4940\n",
      "    macro avg       0.42      0.40      0.41      4940\n",
      " weighted avg       0.89      0.90      0.89      4940\n",
      "\n",
      "\n",
      "Location#Easy_to_find:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.97      0.95      3945\n",
      "     negative       0.70      0.51      0.59       177\n",
      "      neutral       0.00      0.00      0.00       106\n",
      "     positive       0.80      0.79      0.79       712\n",
      "\n",
      "     accuracy                           0.91      4940\n",
      "    macro avg       0.61      0.57      0.58      4940\n",
      " weighted avg       0.89      0.91      0.90      4940\n",
      "\n",
      "\n",
      "Service#Queue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.90      0.99      0.94      4206\n",
      "     negative       0.59      0.17      0.26       203\n",
      "      neutral       0.35      0.23      0.28       298\n",
      "     positive       0.25      0.06      0.10       233\n",
      "\n",
      "     accuracy                           0.87      4940\n",
      "    macro avg       0.52      0.36      0.40      4940\n",
      " weighted avg       0.82      0.87      0.83      4940\n",
      "\n",
      "\n",
      "Service#Hospitality:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.87      0.91      0.89      2065\n",
      "     negative       0.77      0.60      0.67       471\n",
      "      neutral       0.55      0.47      0.51       630\n",
      "     positive       0.86      0.91      0.88      1774\n",
      "\n",
      "     accuracy                           0.83      4940\n",
      "    macro avg       0.76      0.72      0.74      4940\n",
      " weighted avg       0.82      0.83      0.82      4940\n",
      "\n",
      "\n",
      "Service#Parking:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.99      0.99      0.99      4617\n",
      "     negative       0.38      0.16      0.23        68\n",
      "      neutral       0.00      0.00      0.00        78\n",
      "     positive       0.52      0.85      0.64       177\n",
      "\n",
      "     accuracy                           0.96      4940\n",
      "    macro avg       0.47      0.50      0.47      4940\n",
      " weighted avg       0.95      0.96      0.95      4940\n",
      "\n",
      "\n",
      "Service#Timely:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.97      0.97      0.97      4186\n",
      "     negative       0.62      0.72      0.67       253\n",
      "      neutral       0.00      0.00      0.00       104\n",
      "     positive       0.72      0.83      0.77       397\n",
      "\n",
      "     accuracy                           0.92      4940\n",
      "    macro avg       0.58      0.63      0.60      4940\n",
      " weighted avg       0.91      0.92      0.92      4940\n",
      "\n",
      "\n",
      "Price#Level:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.85      0.89      2425\n",
      "     negative       0.76      0.78      0.77       632\n",
      "      neutral       0.63      0.60      0.62      1089\n",
      "     positive       0.60      0.77      0.67       794\n",
      "\n",
      "     accuracy                           0.77      4940\n",
      "    macro avg       0.73      0.75      0.74      4940\n",
      " weighted avg       0.79      0.77      0.78      4940\n",
      "\n",
      "\n",
      "Price#Cost_effective:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.93      0.93      3819\n",
      "     negative       0.49      0.38      0.43       111\n",
      "      neutral       0.00      0.00      0.00       158\n",
      "     positive       0.67      0.84      0.74       852\n",
      "\n",
      "     accuracy                           0.87      4940\n",
      "    macro avg       0.52      0.54      0.53      4940\n",
      " weighted avg       0.85      0.87      0.86      4940\n",
      "\n",
      "\n",
      "Price#Discount:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.96      0.91      0.94      3329\n",
      "     negative       0.33      0.01      0.02       104\n",
      "      neutral       0.53      0.85      0.65       758\n",
      "     positive       0.80      0.60      0.69       749\n",
      "\n",
      "     accuracy                           0.84      4940\n",
      "    macro avg       0.66      0.59      0.57      4940\n",
      " weighted avg       0.86      0.84      0.84      4940\n",
      "\n",
      "\n",
      "Ambience#Decoration:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.90      0.91      2703\n",
      "     negative       0.43      0.15      0.22       101\n",
      "      neutral       0.61      0.46      0.52       411\n",
      "     positive       0.80      0.92      0.85      1725\n",
      "\n",
      "     accuracy                           0.85      4940\n",
      "    macro avg       0.69      0.60      0.63      4940\n",
      " weighted avg       0.85      0.85      0.84      4940\n",
      "\n",
      "\n",
      "Ambience#Noise:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.89      0.94      0.91      3451\n",
      "     negative       0.85      0.49      0.63       166\n",
      "      neutral       0.69      0.47      0.56       212\n",
      "     positive       0.78      0.74      0.76      1111\n",
      "\n",
      "     accuracy                           0.86      4940\n",
      "    macro avg       0.80      0.66      0.72      4940\n",
      " weighted avg       0.86      0.86      0.85      4940\n",
      "\n",
      "\n",
      "Ambience#Space:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.89      0.89      0.89      3129\n",
      "     negative       0.67      0.53      0.59       248\n",
      "      neutral       0.61      0.48      0.54       399\n",
      "     positive       0.74      0.82      0.78      1164\n",
      "\n",
      "     accuracy                           0.82      4940\n",
      "    macro avg       0.73      0.68      0.70      4940\n",
      " weighted avg       0.82      0.82      0.82      4940\n",
      "\n",
      "\n",
      "Ambience#Sanitary:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.90      0.93      0.91      3169\n",
      "     negative       0.64      0.43      0.52       221\n",
      "      neutral       0.63      0.43      0.51       223\n",
      "     positive       0.82      0.83      0.83      1327\n",
      "\n",
      "     accuracy                           0.86      4940\n",
      "    macro avg       0.75      0.66      0.69      4940\n",
      " weighted avg       0.85      0.86      0.85      4940\n",
      "\n",
      "\n",
      "Food#Portion:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.87      0.80      0.83      2759\n",
      "     negative       0.62      0.59      0.60       452\n",
      "      neutral       0.56      0.10      0.17       446\n",
      "     positive       0.59      0.87      0.70      1283\n",
      "\n",
      "     accuracy                           0.73      4940\n",
      "    macro avg       0.66      0.59      0.58      4940\n",
      " weighted avg       0.75      0.73      0.72      4940\n",
      "\n",
      "\n",
      "Food#Taste:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.70      0.45      0.55       268\n",
      "     negative       0.72      0.29      0.42       194\n",
      "      neutral       0.74      0.70      0.72      1904\n",
      "     positive       0.77      0.87      0.82      2574\n",
      "\n",
      "     accuracy                           0.76      4940\n",
      "    macro avg       0.73      0.58      0.63      4940\n",
      " weighted avg       0.76      0.76      0.75      4940\n",
      "\n",
      "\n",
      "Food#Appearance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.84      0.95      0.89      3681\n",
      "     negative       0.33      0.05      0.09       141\n",
      "      neutral       0.00      0.00      0.00       217\n",
      "     positive       0.67      0.54      0.60       901\n",
      "\n",
      "     accuracy                           0.81      4940\n",
      "    macro avg       0.46      0.39      0.39      4940\n",
      " weighted avg       0.75      0.81      0.77      4940\n",
      "\n",
      "\n",
      "Food#Recommend:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.90      0.98      0.94      4042\n",
      "     negative       0.62      0.45      0.52       118\n",
      "      neutral       0.67      0.02      0.04        91\n",
      "     positive       0.76      0.53      0.63       689\n",
      "\n",
      "     accuracy                           0.89      4940\n",
      "    macro avg       0.74      0.49      0.53      4940\n",
      " weighted avg       0.87      0.89      0.87      4940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 2304/2304 [07:46<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Average Training Loss: 6.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Dev: 100%|██████████| 309/309 [00:27<00:00, 11.40it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev Results:\n",
      "\n",
      "Location#Transportation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.97      0.97      0.97      3964\n",
      "     negative       0.53      0.52      0.53        50\n",
      "      neutral       0.00      0.00      0.00        42\n",
      "     positive       0.84      0.89      0.87       884\n",
      "\n",
      "     accuracy                           0.94      4940\n",
      "    macro avg       0.59      0.60      0.59      4940\n",
      " weighted avg       0.93      0.94      0.94      4940\n",
      "\n",
      "\n",
      "Location#Downtown:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.95      0.94      4061\n",
      "     negative       0.00      0.00      0.00        23\n",
      "      neutral       0.00      0.00      0.00        26\n",
      "     positive       0.73      0.71      0.72       830\n",
      "\n",
      "     accuracy                           0.90      4940\n",
      "    macro avg       0.41      0.41      0.41      4940\n",
      " weighted avg       0.89      0.90      0.89      4940\n",
      "\n",
      "\n",
      "Location#Easy_to_find:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.98      0.96      3945\n",
      "     negative       0.64      0.60      0.62       177\n",
      "      neutral       0.40      0.02      0.04       106\n",
      "     positive       0.89      0.76      0.82       712\n",
      "\n",
      "     accuracy                           0.92      4940\n",
      "    macro avg       0.72      0.59      0.61      4940\n",
      " weighted avg       0.90      0.92      0.90      4940\n",
      "\n",
      "\n",
      "Service#Queue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.97      0.95      4206\n",
      "     negative       0.48      0.65      0.55       203\n",
      "      neutral       0.41      0.16      0.23       298\n",
      "     positive       0.49      0.47      0.48       233\n",
      "\n",
      "     accuracy                           0.88      4940\n",
      "    macro avg       0.58      0.56      0.55      4940\n",
      " weighted avg       0.87      0.88      0.87      4940\n",
      "\n",
      "\n",
      "Service#Hospitality:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.90      0.89      0.89      2065\n",
      "     negative       0.88      0.50      0.64       471\n",
      "      neutral       0.54      0.54      0.54       630\n",
      "     positive       0.84      0.93      0.88      1774\n",
      "\n",
      "     accuracy                           0.83      4940\n",
      "    macro avg       0.79      0.72      0.74      4940\n",
      " weighted avg       0.83      0.83      0.82      4940\n",
      "\n",
      "\n",
      "Service#Parking:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.99      0.99      0.99      4617\n",
      "     negative       0.49      0.38      0.43        68\n",
      "      neutral       0.00      0.00      0.00        78\n",
      "     positive       0.56      0.81      0.66       177\n",
      "\n",
      "     accuracy                           0.96      4940\n",
      "    macro avg       0.51      0.55      0.52      4940\n",
      " weighted avg       0.95      0.96      0.96      4940\n",
      "\n",
      "\n",
      "Service#Timely:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.98      0.96      0.97      4186\n",
      "     negative       0.63      0.84      0.72       253\n",
      "      neutral       0.43      0.12      0.19       104\n",
      "     positive       0.75      0.86      0.80       397\n",
      "\n",
      "     accuracy                           0.93      4940\n",
      "    macro avg       0.70      0.70      0.67      4940\n",
      " weighted avg       0.93      0.93      0.93      4940\n",
      "\n",
      "\n",
      "Price#Level:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.89      0.90      2425\n",
      "     negative       0.80      0.79      0.79       632\n",
      "      neutral       0.64      0.72      0.67      1089\n",
      "     positive       0.73      0.68      0.70       794\n",
      "\n",
      "     accuracy                           0.80      4940\n",
      "    macro avg       0.77      0.77      0.77      4940\n",
      " weighted avg       0.81      0.80      0.80      4940\n",
      "\n",
      "\n",
      "Price#Cost_effective:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.94      0.94      3819\n",
      "     negative       0.59      0.45      0.51       111\n",
      "      neutral       0.69      0.22      0.33       158\n",
      "     positive       0.71      0.84      0.77       852\n",
      "\n",
      "     accuracy                           0.89      4940\n",
      "    macro avg       0.73      0.61      0.64      4940\n",
      " weighted avg       0.89      0.89      0.88      4940\n",
      "\n",
      "\n",
      "Price#Discount:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.96      0.91      0.94      3329\n",
      "     negative       0.00      0.00      0.00       104\n",
      "      neutral       0.59      0.70      0.64       758\n",
      "     positive       0.65      0.78      0.71       749\n",
      "\n",
      "     accuracy                           0.84      4940\n",
      "    macro avg       0.55      0.60      0.57      4940\n",
      " weighted avg       0.84      0.84      0.84      4940\n",
      "\n",
      "\n",
      "Ambience#Decoration:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.93      0.92      2703\n",
      "     negative       0.66      0.23      0.34       101\n",
      "      neutral       0.62      0.49      0.55       411\n",
      "     positive       0.84      0.89      0.87      1725\n",
      "\n",
      "     accuracy                           0.86      4940\n",
      "    macro avg       0.76      0.63      0.67      4940\n",
      " weighted avg       0.86      0.86      0.86      4940\n",
      "\n",
      "\n",
      "Ambience#Noise:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.94      0.93      3451\n",
      "     negative       0.70      0.75      0.73       166\n",
      "      neutral       0.77      0.51      0.61       212\n",
      "     positive       0.79      0.77      0.78      1111\n",
      "\n",
      "     accuracy                           0.88      4940\n",
      "    macro avg       0.80      0.74      0.76      4940\n",
      " weighted avg       0.87      0.88      0.87      4940\n",
      "\n",
      "\n",
      "Ambience#Space:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.89      0.92      0.90      3129\n",
      "     negative       0.67      0.68      0.67       248\n",
      "      neutral       0.68      0.54      0.60       399\n",
      "     positive       0.79      0.78      0.79      1164\n",
      "\n",
      "     accuracy                           0.84      4940\n",
      "    macro avg       0.76      0.73      0.74      4940\n",
      " weighted avg       0.84      0.84      0.84      4940\n",
      "\n",
      "\n",
      "Ambience#Sanitary:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.92      0.93      0.92      3169\n",
      "     negative       0.65      0.72      0.69       221\n",
      "      neutral       0.70      0.43      0.53       223\n",
      "     positive       0.83      0.85      0.84      1327\n",
      "\n",
      "     accuracy                           0.87      4940\n",
      "    macro avg       0.77      0.73      0.74      4940\n",
      " weighted avg       0.87      0.87      0.87      4940\n",
      "\n",
      "\n",
      "Food#Portion:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.86      0.89      0.87      2759\n",
      "     negative       0.58      0.73      0.65       452\n",
      "      neutral       0.60      0.31      0.41       446\n",
      "     positive       0.77      0.77      0.77      1283\n",
      "\n",
      "     accuracy                           0.79      4940\n",
      "    macro avg       0.70      0.67      0.67      4940\n",
      " weighted avg       0.78      0.79      0.78      4940\n",
      "\n",
      "\n",
      "Food#Taste:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.76      0.46      0.57       268\n",
      "     negative       0.68      0.42      0.52       194\n",
      "      neutral       0.72      0.79      0.75      1904\n",
      "     positive       0.82      0.83      0.83      2574\n",
      "\n",
      "     accuracy                           0.78      4940\n",
      "    macro avg       0.75      0.62      0.67      4940\n",
      " weighted avg       0.78      0.78      0.77      4940\n",
      "\n",
      "\n",
      "Food#Appearance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.85      0.93      0.89      3681\n",
      "     negative       0.48      0.18      0.26       141\n",
      "      neutral       0.33      0.04      0.07       217\n",
      "     positive       0.64      0.61      0.62       901\n",
      "\n",
      "     accuracy                           0.81      4940\n",
      "    macro avg       0.58      0.44      0.46      4940\n",
      " weighted avg       0.78      0.81      0.79      4940\n",
      "\n",
      "\n",
      "Food#Recommend:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.96      0.94      4042\n",
      "     negative       0.58      0.59      0.59       118\n",
      "      neutral       0.48      0.15      0.23        91\n",
      "     positive       0.74      0.68      0.71       689\n",
      "\n",
      "     accuracy                           0.90      4940\n",
      "    macro avg       0.68      0.60      0.62      4940\n",
      " weighted avg       0.89      0.90      0.89      4940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 2304/2304 [07:47<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Average Training Loss: 6.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Dev: 100%|██████████| 309/309 [00:27<00:00, 11.43it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev Results:\n",
      "\n",
      "Location#Transportation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.97      0.97      0.97      3964\n",
      "     negative       0.58      0.36      0.44        50\n",
      "      neutral       0.00      0.00      0.00        42\n",
      "     positive       0.84      0.91      0.87       884\n",
      "\n",
      "     accuracy                           0.94      4940\n",
      "    macro avg       0.60      0.56      0.57      4940\n",
      " weighted avg       0.94      0.94      0.94      4940\n",
      "\n",
      "\n",
      "Location#Downtown:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.94      0.94      4061\n",
      "     negative       0.20      0.04      0.07        23\n",
      "      neutral       0.00      0.00      0.00        26\n",
      "     positive       0.71      0.77      0.74       830\n",
      "\n",
      "     accuracy                           0.90      4940\n",
      "    macro avg       0.46      0.44      0.44      4940\n",
      " weighted avg       0.90      0.90      0.90      4940\n",
      "\n",
      "\n",
      "Location#Easy_to_find:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.96      0.96      0.96      3945\n",
      "     negative       0.59      0.83      0.69       177\n",
      "      neutral       0.17      0.01      0.02       106\n",
      "     positive       0.82      0.83      0.82       712\n",
      "\n",
      "     accuracy                           0.92      4940\n",
      "    macro avg       0.63      0.66      0.62      4940\n",
      " weighted avg       0.91      0.92      0.91      4940\n",
      "\n",
      "\n",
      "Service#Queue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.95      0.96      0.96      4206\n",
      "     negative       0.61      0.56      0.59       203\n",
      "      neutral       0.39      0.39      0.39       298\n",
      "     positive       0.56      0.51      0.53       233\n",
      "\n",
      "     accuracy                           0.89      4940\n",
      "    macro avg       0.63      0.60      0.62      4940\n",
      " weighted avg       0.89      0.89      0.89      4940\n",
      "\n",
      "\n",
      "Service#Hospitality:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.88      0.89      2065\n",
      "     negative       0.75      0.77      0.76       471\n",
      "      neutral       0.64      0.49      0.56       630\n",
      "     positive       0.83      0.93      0.88      1774\n",
      "\n",
      "     accuracy                           0.84      4940\n",
      "    macro avg       0.78      0.77      0.77      4940\n",
      " weighted avg       0.83      0.84      0.83      4940\n",
      "\n",
      "\n",
      "Service#Parking:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.99      0.99      0.99      4617\n",
      "     negative       0.58      0.74      0.65        68\n",
      "      neutral       0.37      0.09      0.14        78\n",
      "     positive       0.65      0.84      0.73       177\n",
      "\n",
      "     accuracy                           0.97      4940\n",
      "    macro avg       0.65      0.66      0.63      4940\n",
      " weighted avg       0.97      0.97      0.96      4940\n",
      "\n",
      "\n",
      "Service#Timely:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.97      0.97      0.97      4186\n",
      "     negative       0.71      0.74      0.72       253\n",
      "      neutral       0.47      0.16      0.24       104\n",
      "     positive       0.75      0.86      0.80       397\n",
      "\n",
      "     accuracy                           0.93      4940\n",
      "    macro avg       0.73      0.68      0.68      4940\n",
      " weighted avg       0.93      0.93      0.93      4940\n",
      "\n",
      "\n",
      "Price#Level:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.92      0.88      0.90      2425\n",
      "     negative       0.79      0.78      0.79       632\n",
      "      neutral       0.63      0.73      0.68      1089\n",
      "     positive       0.71      0.68      0.69       794\n",
      "\n",
      "     accuracy                           0.80      4940\n",
      "    macro avg       0.76      0.76      0.76      4940\n",
      " weighted avg       0.81      0.80      0.80      4940\n",
      "\n",
      "\n",
      "Price#Cost_effective:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.95      0.92      0.93      3819\n",
      "     negative       0.52      0.43      0.47       111\n",
      "      neutral       0.63      0.24      0.35       158\n",
      "     positive       0.69      0.87      0.77       852\n",
      "\n",
      "     accuracy                           0.88      4940\n",
      "    macro avg       0.70      0.62      0.63      4940\n",
      " weighted avg       0.88      0.88      0.88      4940\n",
      "\n",
      "\n",
      "Price#Discount:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.95      0.94      0.94      3329\n",
      "     negative       0.50      0.01      0.02       104\n",
      "      neutral       0.59      0.76      0.67       758\n",
      "     positive       0.79      0.68      0.73       749\n",
      "\n",
      "     accuracy                           0.86      4940\n",
      "    macro avg       0.71      0.60      0.59      4940\n",
      " weighted avg       0.86      0.86      0.85      4940\n",
      "\n",
      "\n",
      "Ambience#Decoration:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.92      0.92      0.92      2703\n",
      "     negative       0.57      0.33      0.42       101\n",
      "      neutral       0.64      0.54      0.59       411\n",
      "     positive       0.84      0.91      0.87      1725\n",
      "\n",
      "     accuracy                           0.87      4940\n",
      "    macro avg       0.74      0.67      0.70      4940\n",
      " weighted avg       0.87      0.87      0.87      4940\n",
      "\n",
      "\n",
      "Ambience#Noise:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.94      0.92      3451\n",
      "     negative       0.79      0.72      0.75       166\n",
      "      neutral       0.75      0.49      0.59       212\n",
      "     positive       0.79      0.79      0.79      1111\n",
      "\n",
      "     accuracy                           0.88      4940\n",
      "    macro avg       0.81      0.73      0.77      4940\n",
      " weighted avg       0.87      0.88      0.87      4940\n",
      "\n",
      "\n",
      "Ambience#Space:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.91      0.91      3129\n",
      "     negative       0.67      0.70      0.69       248\n",
      "      neutral       0.65      0.64      0.65       399\n",
      "     positive       0.79      0.79      0.79      1164\n",
      "\n",
      "     accuracy                           0.85      4940\n",
      "    macro avg       0.75      0.76      0.76      4940\n",
      " weighted avg       0.85      0.85      0.85      4940\n",
      "\n",
      "\n",
      "Ambience#Sanitary:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.92      0.92      0.92      3169\n",
      "     negative       0.68      0.64      0.66       221\n",
      "      neutral       0.71      0.42      0.53       223\n",
      "     positive       0.81      0.88      0.84      1327\n",
      "\n",
      "     accuracy                           0.88      4940\n",
      "    macro avg       0.78      0.72      0.74      4940\n",
      " weighted avg       0.87      0.88      0.87      4940\n",
      "\n",
      "\n",
      "Food#Portion:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.86      0.89      0.87      2759\n",
      "     negative       0.69      0.62      0.65       452\n",
      "      neutral       0.61      0.40      0.48       446\n",
      "     positive       0.74      0.80      0.77      1283\n",
      "\n",
      "     accuracy                           0.80      4940\n",
      "    macro avg       0.73      0.68      0.70      4940\n",
      " weighted avg       0.79      0.80      0.79      4940\n",
      "\n",
      "\n",
      "Food#Taste:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.66      0.61      0.63       268\n",
      "     negative       0.66      0.48      0.56       194\n",
      "      neutral       0.81      0.61      0.70      1904\n",
      "     positive       0.75      0.91      0.82      2574\n",
      "\n",
      "     accuracy                           0.76      4940\n",
      "    macro avg       0.72      0.65      0.68      4940\n",
      " weighted avg       0.77      0.76      0.75      4940\n",
      "\n",
      "\n",
      "Food#Appearance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.86      0.93      0.89      3681\n",
      "     negative       0.50      0.20      0.28       141\n",
      "      neutral       0.52      0.06      0.11       217\n",
      "     positive       0.65      0.62      0.64       901\n",
      "\n",
      "     accuracy                           0.81      4940\n",
      "    macro avg       0.63      0.45      0.48      4940\n",
      " weighted avg       0.79      0.81      0.79      4940\n",
      "\n",
      "\n",
      "Food#Recommend:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.94      0.94      4042\n",
      "     negative       0.74      0.64      0.68       118\n",
      "      neutral       0.61      0.21      0.31        91\n",
      "     positive       0.65      0.72      0.68       689\n",
      "\n",
      "     accuracy                           0.89      4940\n",
      "    macro avg       0.74      0.63      0.65      4940\n",
      " weighted avg       0.89      0.89      0.88      4940\n",
      "\n",
      "\n",
      "Evaluating on Test Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test: 100%|██████████| 309/309 [00:26<00:00, 11.58it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "\n",
      "Location#Transportation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.97      0.97      0.97      3962\n",
      "     negative       0.72      0.43      0.54        68\n",
      "      neutral       0.00      0.00      0.00        47\n",
      "     positive       0.83      0.90      0.87       863\n",
      "\n",
      "     accuracy                           0.94      4940\n",
      "    macro avg       0.63      0.57      0.59      4940\n",
      " weighted avg       0.93      0.94      0.94      4940\n",
      "\n",
      "\n",
      "Location#Downtown:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.94      0.94      4070\n",
      "     negative       0.33      0.08      0.13        24\n",
      "      neutral       0.00      0.00      0.00        22\n",
      "     positive       0.73      0.75      0.74       824\n",
      "\n",
      "     accuracy                           0.90      4940\n",
      "    macro avg       0.50      0.45      0.45      4940\n",
      " weighted avg       0.90      0.90      0.90      4940\n",
      "\n",
      "\n",
      "Location#Easy_to_find:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.95      0.96      0.96      3958\n",
      "     negative       0.64      0.81      0.71       186\n",
      "      neutral       0.75      0.03      0.05       114\n",
      "     positive       0.81      0.84      0.82       682\n",
      "\n",
      "     accuracy                           0.92      4940\n",
      "    macro avg       0.79      0.66      0.64      4940\n",
      " weighted avg       0.92      0.92      0.91      4940\n",
      "\n",
      "\n",
      "Service#Queue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.96      0.96      0.96      4212\n",
      "     negative       0.66      0.58      0.62       218\n",
      "      neutral       0.35      0.45      0.40       258\n",
      "     positive       0.60      0.52      0.56       252\n",
      "\n",
      "     accuracy                           0.89      4940\n",
      "    macro avg       0.64      0.63      0.63      4940\n",
      " weighted avg       0.90      0.89      0.89      4940\n",
      "\n",
      "\n",
      "Service#Hospitality:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.87      0.89      2137\n",
      "     negative       0.74      0.76      0.75       476\n",
      "      neutral       0.56      0.46      0.50       598\n",
      "     positive       0.84      0.93      0.89      1729\n",
      "\n",
      "     accuracy                           0.83      4940\n",
      "    macro avg       0.76      0.76      0.76      4940\n",
      " weighted avg       0.83      0.83      0.83      4940\n",
      "\n",
      "\n",
      "Service#Parking:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.99      0.99      0.99      4614\n",
      "     negative       0.57      0.61      0.59        72\n",
      "      neutral       0.21      0.04      0.07        69\n",
      "     positive       0.68      0.87      0.76       185\n",
      "\n",
      "     accuracy                           0.97      4940\n",
      "    macro avg       0.61      0.63      0.60      4940\n",
      " weighted avg       0.96      0.97      0.97      4940\n",
      "\n",
      "\n",
      "Service#Timely:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.97      0.97      0.97      4180\n",
      "     negative       0.71      0.73      0.72       261\n",
      "      neutral       0.55      0.23      0.32       102\n",
      "     positive       0.80      0.85      0.82       397\n",
      "\n",
      "     accuracy                           0.94      4940\n",
      "    macro avg       0.75      0.69      0.71      4940\n",
      " weighted avg       0.93      0.94      0.93      4940\n",
      "\n",
      "\n",
      "Price#Level:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.92      0.89      0.90      2505\n",
      "     negative       0.78      0.81      0.80       622\n",
      "      neutral       0.68      0.71      0.69      1087\n",
      "     positive       0.69      0.72      0.71       726\n",
      "\n",
      "     accuracy                           0.81      4940\n",
      "    macro avg       0.77      0.78      0.77      4940\n",
      " weighted avg       0.82      0.81      0.81      4940\n",
      "\n",
      "\n",
      "Price#Cost_effective:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.95      0.92      0.93      3863\n",
      "     negative       0.66      0.52      0.59       124\n",
      "      neutral       0.62      0.29      0.39       135\n",
      "     positive       0.67      0.85      0.75       818\n",
      "\n",
      "     accuracy                           0.88      4940\n",
      "    macro avg       0.73      0.65      0.67      4940\n",
      " weighted avg       0.89      0.88      0.88      4940\n",
      "\n",
      "\n",
      "Price#Discount:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.94      0.94      3384\n",
      "     negative       0.00      0.00      0.00        92\n",
      "      neutral       0.59      0.73      0.65       761\n",
      "     positive       0.78      0.69      0.73       703\n",
      "\n",
      "     accuracy                           0.85      4940\n",
      "    macro avg       0.58      0.59      0.58      4940\n",
      " weighted avg       0.85      0.85      0.85      4940\n",
      "\n",
      "\n",
      "Ambience#Decoration:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.92      0.92      2805\n",
      "     negative       0.50      0.27      0.35       106\n",
      "      neutral       0.61      0.54      0.57       399\n",
      "     positive       0.84      0.90      0.87      1630\n",
      "\n",
      "     accuracy                           0.87      4940\n",
      "    macro avg       0.72      0.66      0.68      4940\n",
      " weighted avg       0.86      0.87      0.87      4940\n",
      "\n",
      "\n",
      "Ambience#Noise:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.95      0.93      3497\n",
      "     negative       0.77      0.73      0.75       162\n",
      "      neutral       0.71      0.44      0.55       242\n",
      "     positive       0.79      0.77      0.78      1039\n",
      "\n",
      "     accuracy                           0.88      4940\n",
      "    macro avg       0.80      0.72      0.75      4940\n",
      " weighted avg       0.87      0.88      0.87      4940\n",
      "\n",
      "\n",
      "Ambience#Space:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.91      0.91      0.91      3197\n",
      "     negative       0.71      0.64      0.67       278\n",
      "      neutral       0.64      0.63      0.63       421\n",
      "     positive       0.76      0.78      0.77      1044\n",
      "\n",
      "     accuracy                           0.84      4940\n",
      "    macro avg       0.75      0.74      0.75      4940\n",
      " weighted avg       0.84      0.84      0.84      4940\n",
      "\n",
      "\n",
      "Ambience#Sanitary:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.93      0.92      0.92      3307\n",
      "     negative       0.64      0.61      0.63       222\n",
      "      neutral       0.66      0.44      0.53       213\n",
      "     positive       0.78      0.86      0.82      1198\n",
      "\n",
      "     accuracy                           0.87      4940\n",
      "    macro avg       0.75      0.71      0.72      4940\n",
      " weighted avg       0.87      0.87      0.87      4940\n",
      "\n",
      "\n",
      "Food#Portion:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.87      0.89      0.88      2842\n",
      "     negative       0.71      0.61      0.65       461\n",
      "      neutral       0.54      0.40      0.46       373\n",
      "     positive       0.75      0.80      0.77      1264\n",
      "\n",
      "     accuracy                           0.80      4940\n",
      "    macro avg       0.72      0.67      0.69      4940\n",
      " weighted avg       0.80      0.80      0.80      4940\n",
      "\n",
      "\n",
      "Food#Taste:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.66      0.54      0.59       261\n",
      "     negative       0.67      0.52      0.59       207\n",
      "      neutral       0.80      0.62      0.70      1916\n",
      "     positive       0.75      0.91      0.83      2556\n",
      "\n",
      "     accuracy                           0.76      4940\n",
      "    macro avg       0.72      0.65      0.68      4940\n",
      " weighted avg       0.76      0.76      0.75      4940\n",
      "\n",
      "\n",
      "Food#Appearance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.85      0.93      0.89      3685\n",
      "     negative       0.61      0.24      0.34       143\n",
      "      neutral       0.45      0.07      0.12       192\n",
      "     positive       0.65      0.58      0.61       920\n",
      "\n",
      "     accuracy                           0.81      4940\n",
      "    macro avg       0.64      0.45      0.49      4940\n",
      " weighted avg       0.79      0.81      0.79      4940\n",
      "\n",
      "\n",
      "Food#Recommend:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_mentioned       0.94      0.95      0.94      4079\n",
      "     negative       0.66      0.65      0.66        91\n",
      "      neutral       0.53      0.12      0.19        77\n",
      "     positive       0.70      0.72      0.71       693\n",
      "\n",
      "     accuracy                           0.90      4940\n",
      "    macro avg       0.71      0.61      0.62      4940\n",
      " weighted avg       0.89      0.90      0.89      4940\n",
      "\n",
      "\n",
      "Saving BERT model...\n",
      "BERT model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "### 5. Bidirectional Encoder Representations from Transformers (BERT)\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 16  # BERT-based model batch size\n",
    "LEARNING_RATE = 0.00005  # BERT learning rate\n",
    "EPOCHS = 3  # Number of epochs\n",
    "MAX_SEQ_LENGTH = 512  # Maximum sequence length\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_LABELS_PER_ASPECT = 4  # Positive, Neutral, Negative, Not_Mentioned\n",
    "\n",
    "\n",
    "# Define the custom dataset class\n",
    "class RestaurantReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_length):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels  # DataFrame with 18 aspect columns\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews.iloc[idx])\n",
    "        label_dict = {}\n",
    "\n",
    "        # Convert labels to numerical values: -2 (not_mentioned) -> 0, -1 -> 1, 0 -> 2, 1 -> 3\n",
    "        for aspect in self.labels.columns:\n",
    "            label = self.labels[aspect].iloc[idx]\n",
    "            if label == \"not_mentioned\":\n",
    "                label_num = 0\n",
    "            elif label == \"negative\":\n",
    "                label_num = 1\n",
    "            elif label == \"neutral\":\n",
    "                label_num = 2\n",
    "            elif label == \"positive\":\n",
    "                label_num = 3\n",
    "            label_dict[aspect] = label_num\n",
    "\n",
    "        # Tokenize the review\n",
    "        encoding = self.tokenizer(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(\n",
    "                [label_dict[asp] for asp in self.labels.columns], dtype=torch.long\n",
    "            ),\n",
    "        }\n",
    "\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "# Define a custom multi-task BERT model\n",
    "class MultiTaskBert(torch.nn.Module):\n",
    "    def __init__(self, num_aspects, num_labels_per_aspect):\n",
    "        super(MultiTaskBert, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifiers = torch.nn.ModuleList(\n",
    "            [torch.nn.Linear(768, num_labels_per_aspect) for _ in range(num_aspects)]\n",
    "        )  # 768 is BERT hidden size\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        logits = [classifier(pooled_output) for classifier in self.classifiers]\n",
    "        return logits  # List of logits for each aspect\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = MultiTaskBert(\n",
    "    num_aspects=len(aspect_columns), num_labels_per_aspect=NUM_LABELS_PER_ASPECT\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = RestaurantReviewDataset(X_train, y_train, tokenizer, MAX_SEQ_LENGTH)\n",
    "dev_dataset = RestaurantReviewDataset(X_dev, y_dev, tokenizer, MAX_SEQ_LENGTH)\n",
    "test_dataset = RestaurantReviewDataset(X_test, y_test, tokenizer, MAX_SEQ_LENGTH)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "\n",
    "# Loss function (one for each aspect)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, dev_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)  # Shape: [batch_size, num_aspects]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(\n",
    "                input_ids, attention_mask\n",
    "            )  # List of [batch_size, num_labels]\n",
    "\n",
    "            # Compute loss for each aspect and sum\n",
    "            loss = 0\n",
    "            for i, aspect_logits in enumerate(logits):\n",
    "                loss += loss_fn(aspect_logits, labels[:, i])\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Validation\n",
    "        evaluate_model(model, dev_loader, \"Dev\")\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, dataset_name):\n",
    "    model.eval()\n",
    "    all_preds = [[] for _ in range(len(aspect_columns))]\n",
    "    all_labels = [[] for _ in range(len(aspect_columns))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=f\"Evaluating {dataset_name}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            for i, aspect_logits in enumerate(logits):\n",
    "                preds = torch.argmax(aspect_logits, dim=1).cpu().numpy()\n",
    "                all_preds[i].extend(preds)\n",
    "                all_labels[i].extend(labels[:, i].cpu().numpy())\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"\\n{dataset_name} Results:\")\n",
    "    for i, aspect in enumerate(aspect_columns):\n",
    "        print(f\"\\n{aspect}:\")\n",
    "        print(\n",
    "            classification_report(\n",
    "                all_labels[i],\n",
    "                all_preds[i],\n",
    "                target_names=[\"not_mentioned\", \"negative\", \"neutral\", \"positive\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "print(\"Training BERT model...\")\n",
    "train_model(model, train_loader, dev_loader, EPOCHS)\n",
    "\n",
    "print(\"\\nEvaluating on Test Set...\")\n",
    "evaluate_model(model, test_loader, \"Test\")\n",
    "\n",
    "# Save the model\n",
    "print(\"\\nSaving BERT model...\")\n",
    "torch.save(model.state_dict(), \"bert_multitask_model.pth\")\n",
    "print(\"BERT model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifiers): ModuleList(\n",
       "    (0-17): 18 x Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
