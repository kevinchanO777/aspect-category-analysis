{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data and preprocess\n",
    "\n",
    "We are using [ASAP](https://github.com/Meituan-Dianping/asap) dataset authored by Bu et. al. ASAP is a Chinese restaurant review dataset collected from Dianping App. Reviews are written in Chinese and each review is annotated with a star rating from 1 to 5 and 18 different aspects along with the sentiment. \n",
    "\n",
    "\n",
    "Each aspect category for example Location#Transportation is is labeled as 1(Positive), 0(Neutral), −1(Negative), −2(Not-Mentioned). The data is conveniently splited into train, dev, test dataset already.\n",
    "\n",
    "[jieba](https://github.com/fxsjy/jieba) is used \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.244 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    words = jieba.cut(text)\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def convert_sentiment(score):\n",
    "    if score == -2:\n",
    "        return \"not_mentioned\"\n",
    "    elif score == -1:\n",
    "        return \"negative\"\n",
    "    elif score == 0:\n",
    "        return \"neutral\"\n",
    "    else:  # score == 1\n",
    "        return \"positive\"\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Define aspects, e.g. Food#Appearance, Service#Price, etc.\n",
    "    aspect_columns = [col for col in df.columns if col not in [\"id\", \"review\", \"star\"]]\n",
    "    y = df[aspect_columns]\n",
    "\n",
    "    # Convert sentiment scores to categorical labels\n",
    "    y = df[aspect_columns].astype(\"object\")\n",
    "    for col in y.columns:\n",
    "        y.loc[:, col] = y[col].apply(convert_sentiment)\n",
    "\n",
    "    # Data preprocessing\n",
    "    df[\"processed_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "    return df[\"processed_review\"], y, aspect_columns\n",
    "\n",
    "\n",
    "train_path = \"../data/train.csv\"\n",
    "dev_path = \"../data/dev.csv\"\n",
    "test_path = \"../data/test.csv\"\n",
    "\n",
    "X_train, y_train, aspect_columns = load_and_preprocess_data(train_path)\n",
    "X_dev, y_dev, _ = load_and_preprocess_data(dev_path)\n",
    "X_test, y_test, _ = load_and_preprocess_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36850,), (36850, 18)\n",
      "Dev shape: (4940,), (4940, 18)\n",
      "Test shape: (4940,), (4940, 18)\n",
      "\n",
      "Example of the training data:\n",
      "Review: \"状元 楼 饭店 第一次 去 ， 因为 地理位置 优越 ： 在 宁波市 和 义 大道 高 、 大 、 \"\n",
      "Labels: {'Location#Transportation': 'positive', 'Location#Downtown': 'positive', 'Location#Easy_to_find': 'positive', 'Service#Queue': 'not_mentioned', 'Service#Hospitality': 'positive', 'Service#Parking': 'not_mentioned', 'Service#Timely': 'not_mentioned', 'Price#Level': 'not_mentioned', 'Price#Cost_effective': 'not_mentioned', 'Price#Discount': 'not_mentioned', 'Ambience#Decoration': 'positive', 'Ambience#Noise': 'not_mentioned', 'Ambience#Space': 'not_mentioned', 'Ambience#Sanitary': 'not_mentioned', 'Food#Portion': 'not_mentioned', 'Food#Taste': 'positive', 'Food#Appearance': 'not_mentioned', 'Food#Recommend': 'not_mentioned'}\n",
      "\n",
      "Review: \"我 最 爱 他们 家 的 猪手 ， 麻辣 鸡爪 ， 肉片 口磨 ， 道 道菜 都 是 家常菜 的 味\"\n",
      "Labels: {'Location#Transportation': 'positive', 'Location#Downtown': 'not_mentioned', 'Location#Easy_to_find': 'not_mentioned', 'Service#Queue': 'not_mentioned', 'Service#Hospitality': 'positive', 'Service#Parking': 'not_mentioned', 'Service#Timely': 'not_mentioned', 'Price#Level': 'not_mentioned', 'Price#Cost_effective': 'not_mentioned', 'Price#Discount': 'not_mentioned', 'Ambience#Decoration': 'not_mentioned', 'Ambience#Noise': 'not_mentioned', 'Ambience#Space': 'not_mentioned', 'Ambience#Sanitary': 'positive', 'Food#Portion': 'not_mentioned', 'Food#Taste': 'positive', 'Food#Appearance': 'not_mentioned', 'Food#Recommend': 'not_mentioned'}\n",
      "\n",
      "Review: \"我 是 比较 喜欢 荣 新馆 的 ， 因为 材料 新鲜 ， 服务 又 好 ， 价格 适中 ， 但是 \"\n",
      "Labels: {'Location#Transportation': 'not_mentioned', 'Location#Downtown': 'not_mentioned', 'Location#Easy_to_find': 'not_mentioned', 'Service#Queue': 'not_mentioned', 'Service#Hospitality': 'positive', 'Service#Parking': 'not_mentioned', 'Service#Timely': 'not_mentioned', 'Price#Level': 'neutral', 'Price#Cost_effective': 'not_mentioned', 'Price#Discount': 'not_mentioned', 'Ambience#Decoration': 'not_mentioned', 'Ambience#Noise': 'not_mentioned', 'Ambience#Space': 'not_mentioned', 'Ambience#Sanitary': 'not_mentioned', 'Food#Portion': 'not_mentioned', 'Food#Taste': 'neutral', 'Food#Appearance': 'positive', 'Food#Recommend': 'not_mentioned'}\n",
      "\n",
      "Review: \"8.8 秒杀 的 多嘴 肉蟹 煲 ， 第一天 开业 就 去 了 ， 大众 点评 很 给 力 ， 排 \"\n",
      "Labels: {'Location#Transportation': 'not_mentioned', 'Location#Downtown': 'not_mentioned', 'Location#Easy_to_find': 'not_mentioned', 'Service#Queue': 'negative', 'Service#Hospitality': 'positive', 'Service#Parking': 'not_mentioned', 'Service#Timely': 'not_mentioned', 'Price#Level': 'neutral', 'Price#Cost_effective': 'not_mentioned', 'Price#Discount': 'positive', 'Ambience#Decoration': 'not_mentioned', 'Ambience#Noise': 'not_mentioned', 'Ambience#Space': 'not_mentioned', 'Ambience#Sanitary': 'not_mentioned', 'Food#Portion': 'positive', 'Food#Taste': 'positive', 'Food#Appearance': 'not_mentioned', 'Food#Recommend': 'not_mentioned'}\n",
      "\n",
      "Review: \"喜欢 KOI 好多年 了 ， 但是 看着 它 的 价格 在 一路 飙涨 ， 真心 是 有点 越来越 \"\n",
      "Labels: {'Location#Transportation': 'not_mentioned', 'Location#Downtown': 'positive', 'Location#Easy_to_find': 'negative', 'Service#Queue': 'not_mentioned', 'Service#Hospitality': 'not_mentioned', 'Service#Parking': 'not_mentioned', 'Service#Timely': 'not_mentioned', 'Price#Level': 'positive', 'Price#Cost_effective': 'not_mentioned', 'Price#Discount': 'positive', 'Ambience#Decoration': 'not_mentioned', 'Ambience#Noise': 'not_mentioned', 'Ambience#Space': 'not_mentioned', 'Ambience#Sanitary': 'not_mentioned', 'Food#Portion': 'positive', 'Food#Taste': 'positive', 'Food#Appearance': 'not_mentioned', 'Food#Recommend': 'not_mentioned'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Dev shape: {X_dev.shape}, {y_dev.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\\n\")\n",
    "\n",
    "# print example of training data\n",
    "print(\"Example of the training data:\")\n",
    "for i in range(5):\n",
    "    print(f'Review: \"{X_train.iloc[i][:50]}\"\\nLabels: {y_train.iloc[i].to_dict()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subdirectory for EDA plots\n",
    "OUTPUT_DIR = \"eda_plots\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Bar plot colors for sentiment categories\n",
    "SENTIMENTS = [\"not_mentioned\", \"negative\", \"neutral\", \"positive\"]\n",
    "SENTIMENT_COLORS = {\n",
    "    \"not_mentioned\": \"#808080\",  # Gray\n",
    "    \"negative\": \"#FF0000\",  # Red\n",
    "    \"neutral\": \"#1F77B4\",  # Blue\n",
    "    \"positive\": \"#2CA02C\",  # Green\n",
    "}\n",
    "\n",
    "\n",
    "def plot_aspect_mention_frequency(y, dataset_name):\n",
    "    \"\"\"Plot the frequency of aspect mentions in the dataset.\"\"\"\n",
    "    mention_freq = (y != \"not_mentioned\").mean()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=mention_freq.index, y=mention_freq.values)\n",
    "    plt.title(f\"Aspect Mention Frequency in {dataset_name} Dataset\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Proportion of Reviews Mentioning Aspect\")\n",
    "    annotate_bars(ax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(OUTPUT_DIR, f\"aspect_mention_frequency_{dataset_name}.png\")\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_sentiment_distribution(y, dataset_name):\n",
    "    \"\"\"Plot the sentiment distribution for each aspect in the dataset.\"\"\"\n",
    "    for aspect in y.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = sns.countplot(\n",
    "            data=y,\n",
    "            x=aspect,\n",
    "            order=SENTIMENTS,\n",
    "            hue=aspect,\n",
    "            palette=SENTIMENT_COLORS,\n",
    "            legend=False,\n",
    "        )\n",
    "        plt.title(f\"Sentiment Distribution for {aspect} in {dataset_name} Dataset\")\n",
    "        plt.xlabel(\"Sentiment\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        annotate_bars(ax)\n",
    "        plt.savefig(\n",
    "            os.path.join(\n",
    "                OUTPUT_DIR, f\"sentiment_distribution_{aspect}_{dataset_name}.png\"\n",
    "            )\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def annotate_bars(ax):\n",
    "    \"\"\"Annotate bars with their heights, formatting based on value range.\"\"\"\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if height <= 0:\n",
    "            return\n",
    "        if 0 < height < 1:\n",
    "            annotation_text = f\"{height:.2f}\"\n",
    "        else:\n",
    "            # Format as whole number for other values\n",
    "            annotation_text = f\"{int(height)}\"\n",
    "\n",
    "        ax.annotate(\n",
    "            annotation_text,\n",
    "            (p.get_x() + p.get_width() / 2.0, height),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_aspect_mention_distribution(y, dataset_name):\n",
    "    \"\"\"Plot the distribution of the number of aspects mentioned per review.\"\"\"\n",
    "    num_aspects_mentioned_per_review = (y != \"not_mentioned\").sum(axis=1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.histplot(\n",
    "        num_aspects_mentioned_per_review, bins=range(0, len(y.columns) + 1), kde=False\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Distribution of Number of Aspects Mentioned per Review in {dataset_name} Dataset\"\n",
    "    )\n",
    "    plt.xlabel(\"Number of Aspects Mentioned\")\n",
    "    plt.ylabel(\"Number of Reviews\")\n",
    "    annotate_bars(ax)\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"num_aspects_mentioned_{dataset_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def summarize_dataset(y, dataset_name):\n",
    "    \"\"\"Print summary statistics for the dataset.\"\"\"\n",
    "    print(f\"{dataset_name.capitalize()}\")\n",
    "    print(f\"Total reviews: {len(y)}\")\n",
    "\n",
    "    num_aspects_mentioned_per_review = (y != \"not_mentioned\").sum(axis=1)\n",
    "    avg_mentions = num_aspects_mentioned_per_review.mean()\n",
    "\n",
    "    most_mentioned_aspect = (y != \"not_mentioned\").sum().idxmax()\n",
    "    most_mentioned_aspect_count = (y != \"not_mentioned\").sum().max()\n",
    "    most_mentioned_aspect_percentage = (\n",
    "        (y[most_mentioned_aspect] != \"not_mentioned\").sum() / len(y)\n",
    "    ) * 100\n",
    "\n",
    "    least_mentioned_aspect = (y != \"not_mentioned\").sum().idxmin()\n",
    "    least_mentioned_aspect_count = (y != \"not_mentioned\").sum().min()\n",
    "    least_mentioned_aspect_percentage = (\n",
    "        (y[least_mentioned_aspect] != \"not_mentioned\").sum() / len(y)\n",
    "    ) * 100\n",
    "\n",
    "    print(f\"Average number of aspects mentioned per review: {avg_mentions:.2f}\")\n",
    "    print(\n",
    "        f\"Most frequently mentioned aspect: {most_mentioned_aspect} {most_mentioned_aspect_count} ({most_mentioned_aspect_percentage:.2f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Least frequently mentioned aspect: {least_mentioned_aspect} {least_mentioned_aspect_count} ({least_mentioned_aspect_percentage:.2f}%)\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def perform_eda(y, dataset_name):\n",
    "    plot_aspect_mention_frequency(y, dataset_name)\n",
    "    plot_sentiment_distribution(y, dataset_name)\n",
    "    plot_aspect_mention_distribution(y, dataset_name)\n",
    "    summarize_dataset(y, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Total reviews: 36850\n",
      "Average number of aspects mentioned per review: 5.79\n",
      "Most frequently mentioned aspect: Food#Taste 34872 (94.63%)\n",
      "Least frequently mentioned aspect: Service#Parking 2476 (6.72%)\n",
      "\n",
      "Dev\n",
      "Total reviews: 4940\n",
      "Average number of aspects mentioned per review: 5.89\n",
      "Most frequently mentioned aspect: Food#Taste 4672 (94.57%)\n",
      "Least frequently mentioned aspect: Service#Parking 323 (6.54%)\n",
      "\n",
      "Test\n",
      "Total reviews: 4940\n",
      "Average number of aspects mentioned per review: 5.74\n",
      "Most frequently mentioned aspect: Food#Taste 4679 (94.72%)\n",
      "Least frequently mentioned aspect: Service#Parking 326 (6.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_eda(y_train, \"train\")\n",
    "perform_eda(y_dev, \"dev\")\n",
    "perform_eda(y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Word embedding\n",
    "\n",
    "To perform any sort of training, we need to convert raw string (chars) into vectors so that they can be computed. There are plenty of ways to do it including Bag of Words (BoW), Word2vec, GloVe, etc... \n",
    "\n",
    "We shall try them and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Bidirectional Encoder Representations from Transformers (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
